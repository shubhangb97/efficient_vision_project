Using device: cuda
total number of parameters of the network is: 349722828
>>> Training dataset length: 716625
>>> Validation dataset length: 18576
[1,     1]  training loss: 1.177
[1,   201]  training loss: 1.419
[1,   401]  training loss: 1.422
[1,   601]  training loss: 1.425
[1,   801]  training loss: 1.442
[1,  1001]  training loss: 1.455
[1,  1201]  training loss: 1.470
[1,  1401]  training loss: 1.439
[1,  1601]  training loss: 1.456
[1,  1801]  training loss: 1.438
[1,  2001]  training loss: 1.448
[1,  2201]  training loss: 1.471
[1,  2401]  training loss: 1.435
[1,  2601]  training loss: 1.451
[1,  2801]  training loss: 1.444
[1,  3001]  training loss: 1.445
[1,  3201]  training loss: 1.438
[1,  3401]  training loss: 1.441
[1,  3601]  training loss: 1.450
[1,  3801]  training loss: 1.460
[1,  4001]  training loss: 1.453
[1,  4201]  training loss: 1.454
[1,  4401]  training loss: 1.444
[1,  4601]  training loss: 1.431
[1,  4801]  training loss: 1.429
[1,  5001]  training loss: 1.423
[1,  5201]  training loss: 1.438
[1,  5401]  training loss: 1.439
[1,  5601]  training loss: 1.434
[1,  5801]  training loss: 1.435
[1,  6001]  training loss: 1.428
[1,  6201]  training loss: 1.439
[1,  6401]  training loss: 1.439
[1,  6601]  training loss: 1.431
[1,  6801]  training loss: 1.437
[1,  7001]  training loss: 1.435
[1,  7201]  training loss: 1.442
[1,  7401]  training loss: 1.424
[1,  7601]  training loss: 1.444
[1,  7801]  training loss: 1.438
[1,  8001]  training loss: 1.440
[1,  8201]  training loss: 1.430
[1,  8401]  training loss: 1.423
[1,  8601]  training loss: 1.434
[1,  8801]  training loss: 1.441
[1,  9001]  training loss: 1.429
[1,  9201]  training loss: 1.440
[1,  9401]  training loss: 1.431
[1,  9601]  training loss: 1.437
[1,  9801]  training loss: 1.426
[1, 10001]  training loss: 1.429
[1, 10201]  training loss: 1.432
[1, 10401]  training loss: 1.436
[1, 10601]  training loss: 1.430
[1, 10801]  training loss: 1.423
[1, 11001]  training loss: 1.435
[1, 11201]  training loss: 1.434
[1, 11401]  training loss: 1.431
[1, 11601]  training loss: 1.413
[1, 11801]  training loss: 1.429
[1, 12001]  training loss: 1.439
[1, 12201]  training loss: 1.430
[1, 12401]  training loss: 1.432
[1, 12601]  training loss: 1.448
[1, 12801]  training loss: 1.443
[1, 13001]  training loss: 1.412
[1, 13201]  training loss: 1.440
[1, 13401]  training loss: 1.429
[1, 13601]  training loss: 1.426
[1, 13801]  training loss: 1.426
[1, 14001]  training loss: 1.443
[1, 14201]  training loss: 1.448
[1, 14401]  training loss: 1.434
[1, 14601]  training loss: 1.435
[1, 14801]  training loss: 1.448
[1, 15001]  training loss: 1.423
[1, 15201]  training loss: 1.437
[1, 15401]  training loss: 1.444
[1, 15601]  training loss: 1.426
[1, 15801]  training loss: 1.436
[1, 16001]  training loss: 1.448
[1, 16201]  training loss: 1.439
[1, 16401]  training loss: 1.428
[1, 16601]  training loss: 1.432
[1, 16801]  training loss: 1.430
[1, 17001]  training loss: 1.434
[1, 17201]  training loss: 1.438
[1, 17401]  training loss: 1.445
[1, 17601]  training loss: 1.438
[1, 17801]  training loss: 1.428
[1, 18001]  training loss: 1.425
[1, 18201]  training loss: 1.428
[1, 18401]  training loss: 1.440
[1, 18601]  training loss: 1.435
[1, 18801]  training loss: 1.435
[1, 19001]  training loss: 1.414
[1, 19201]  training loss: 1.438
[1, 19401]  training loss: 1.432
[1, 19601]  training loss: 1.433
[1, 19801]  training loss: 1.440
[1, 20001]  training loss: 1.431
[1, 20201]  training loss: 1.431
[1, 20401]  training loss: 1.426
[1, 20601]  training loss: 1.431
[1, 20801]  training loss: 1.438
[1, 21001]  training loss: 1.440
[1, 21201]  training loss: 1.428
[1, 21401]  training loss: 1.436
[1, 21601]  training loss: 1.438
[1, 21801]  training loss: 1.417
[1, 22001]  training loss: 1.440
[1, 22201]  training loss: 1.432
[1,     1]  validation loss: 1.507, metric: 32721.238
[1,   201]  validation loss: 1.504, metric: 30770.044
[1,   401]  validation loss: 1.511, metric: 31317.383
[2,     1]  training loss: 1.434
[2,   201]  training loss: 1.433
[2,   401]  training loss: 1.416
[2,   601]  training loss: 1.433
[2,   801]  training loss: 1.447
[2,  1001]  training loss: 1.441
[2,  1201]  training loss: 1.447
[2,  1401]  training loss: 1.447
[2,  1601]  training loss: 1.439
[2,  1801]  training loss: 1.429
[2,  2001]  training loss: 1.437
[2,  2201]  training loss: 1.430
[2,  2401]  training loss: 1.433
[2,  2601]  training loss: 1.446
[2,  2801]  training loss: 1.434
[2,  3001]  training loss: 1.439
[2,  3201]  training loss: 1.430
[2,  3401]  training loss: 1.443
[2,  3601]  training loss: 1.422
[2,  3801]  training loss: 1.433
[2,  4001]  training loss: 1.439
[2,  4201]  training loss: 1.439
[2,  4401]  training loss: 1.428
[2,  4601]  training loss: 1.448
[2,  4801]  training loss: 1.432
[2,  5001]  training loss: 1.437
[2,  5201]  training loss: 1.439
[2,  5401]  training loss: 1.440
[2,  5601]  training loss: 1.440
[2,  5801]  training loss: 1.433
[2,  6001]  training loss: 1.432
[2,  6201]  training loss: 1.429
[2,  6401]  training loss: 1.441
[2,  6601]  training loss: 1.435
[2,  6801]  training loss: 1.432
[2,  7001]  training loss: 1.436
[2,  7201]  training loss: 1.444
[2,  7401]  training loss: 1.424
[2,  7601]  training loss: 1.441
[2,  7801]  training loss: 1.444
[2,  8001]  training loss: 1.443
[2,  8201]  training loss: 1.446
[2,  8401]  training loss: 1.448
[2,  8601]  training loss: 1.433
[2,  8801]  training loss: 1.443
[2,  9001]  training loss: 1.443
[2,  9201]  training loss: 1.441
[2,  9401]  training loss: 1.440
[2,  9601]  training loss: 1.449
[2,  9801]  training loss: 1.431
[2, 10001]  training loss: 1.439
[2, 10201]  training loss: 1.435
[2, 10401]  training loss: 1.411
[2, 10601]  training loss: 1.445
[2, 10801]  training loss: 1.438
[2, 11001]  training loss: 1.433
[2, 11201]  training loss: 1.443
[2, 11401]  training loss: 1.444
[2, 11601]  training loss: 1.436
[2, 11801]  training loss: 1.446
[2, 12001]  training loss: 1.442
[2, 12201]  training loss: 1.429
[2, 12401]  training loss: 1.436
[2, 12601]  training loss: 1.432
[2, 12801]  training loss: 1.431
[2, 13001]  training loss: 1.440
[2, 13201]  training loss: 1.444
[2, 13401]  training loss: 1.433
[2, 13601]  training loss: 1.432
[2, 13801]  training loss: 1.445
[2, 14001]  training loss: 1.433
[2, 14201]  training loss: 1.441
[2, 14401]  training loss: 1.440
[2, 14601]  training loss: 1.431
[2, 14801]  training loss: 1.437
[2, 15001]  training loss: 1.432
[2, 15201]  training loss: 1.443
[2, 15401]  training loss: 1.441
[2, 15601]  training loss: 1.415
[2, 15801]  training loss: 1.428
[2, 16001]  training loss: 1.429
[2, 16201]  training loss: 1.445
[2, 16401]  training loss: 1.443
[2, 16601]  training loss: 1.451
[2, 16801]  training loss: 1.445
[2, 17001]  training loss: 1.429
[2, 17201]  training loss: 1.436
[2, 17401]  training loss: 1.445
[2, 17601]  training loss: 1.437
[2, 17801]  training loss: 1.446
[2, 18001]  training loss: 1.436
[2, 18201]  training loss: 1.435
[2, 18401]  training loss: 1.440
[2, 18601]  training loss: 1.447
[2, 18801]  training loss: 1.437
[2, 19001]  training loss: 1.444
[2, 19201]  training loss: 1.445
[2, 19401]  training loss: 1.435
[2, 19601]  training loss: 1.438
[2, 19801]  training loss: 1.445
[2, 20001]  training loss: 1.440
[2, 20201]  training loss: 1.440
[2, 20401]  training loss: 1.443
[2, 20601]  training loss: 1.442
[2, 20801]  training loss: 1.442
[2, 21001]  training loss: 1.434
[2, 21201]  training loss: 1.449
[2, 21401]  training loss: 1.426
[2, 21601]  training loss: 1.441
[2, 21801]  training loss: 1.436
[2, 22001]  training loss: 1.432
[2, 22201]  training loss: 1.433
[2,     1]  validation loss: 1.522, metric: 21440.196
[2,   201]  validation loss: 1.528, metric: 21440.456
[2,   401]  validation loss: 1.524, metric: 21433.063
[3,     1]  training loss: 1.446
[3,   201]  training loss: 1.441
[3,   401]  training loss: 1.445
[3,   601]  training loss: 1.440
[3,   801]  training loss: 1.447
[3,  1001]  training loss: 1.432
[3,  1201]  training loss: 1.437
[3,  1401]  training loss: 1.443
[3,  1601]  training loss: 1.448
[3,  1801]  training loss: 1.452
[3,  2001]  training loss: 1.446
[3,  2201]  training loss: 1.450
[3,  2401]  training loss: 1.451
[3,  2601]  training loss: 1.422
[3,  2801]  training loss: 1.433
[3,  3001]  training loss: 1.442
[3,  3201]  training loss: 1.446
[3,  3401]  training loss: 1.434
[3,  3601]  training loss: 1.427
[3,  3801]  training loss: 1.439
[3,  4001]  training loss: 1.444
[3,  4201]  training loss: 1.430
[3,  4401]  training loss: 1.443
[3,  4601]  training loss: 1.448
[3,  4801]  training loss: 1.447
[3,  5001]  training loss: 1.436
[3,  5201]  training loss: 1.440
[3,  5401]  training loss: 1.436
[3,  5601]  training loss: 1.429
[3,  5801]  training loss: 1.437
[3,  6001]  training loss: 1.442
[3,  6201]  training loss: 1.442
[3,  6401]  training loss: 1.445
[3,  6601]  training loss: 1.445
[3,  6801]  training loss: 1.440
[3,  7001]  training loss: 1.437
[3,  7201]  training loss: 1.446
[3,  7401]  training loss: 1.443
[3,  7601]  training loss: 1.436
[3,  7801]  training loss: 1.439
[3,  8001]  training loss: 1.446
[3,  8201]  training loss: 1.447
[3,  8401]  training loss: 1.432
[3,  8601]  training loss: 1.437
[3,  8801]  training loss: 1.424
[3,  9001]  training loss: 1.437
[3,  9201]  training loss: 1.438
[3,  9401]  training loss: 1.445
[3,  9601]  training loss: 1.438
[3,  9801]  training loss: 1.439
[3, 10001]  training loss: 1.432
[3, 10201]  training loss: 1.434
[3, 10401]  training loss: 1.433
[3, 10601]  training loss: 1.439
[3, 10801]  training loss: 1.434
[3, 11001]  training loss: 1.444
[3, 11201]  training loss: 1.440
[3, 11401]  training loss: 1.438
[3, 11601]  training loss: 1.433
[3, 11801]  training loss: 1.435
[3, 12001]  training loss: 1.436
[3, 12201]  training loss: 1.444
[3, 12401]  training loss: 1.449
[3, 12601]  training loss: 1.441
[3, 12801]  training loss: 1.442
[3, 13001]  training loss: 1.434
[3, 13201]  training loss: 1.445
[3, 13401]  training loss: 1.440
[3, 13601]  training loss: 1.442
[3, 13801]  training loss: 1.441
[3, 14001]  training loss: 1.432
[3, 14201]  training loss: 1.430
[3, 14401]  training loss: 1.454
[3, 14601]  training loss: 1.443
[3, 14801]  training loss: 1.447
[3, 15001]  training loss: 1.435
[3, 15201]  training loss: 1.432
[3, 15401]  training loss: 1.445
[3, 15601]  training loss: 1.441
[3, 15801]  training loss: 1.433
[3, 16001]  training loss: 1.439
[3, 16201]  training loss: 1.444
[3, 16401]  training loss: 1.435
[3, 16601]  training loss: 1.449
[3, 16801]  training loss: 1.436
[3, 17001]  training loss: 1.431
[3, 17201]  training loss: 1.441
[3, 17401]  training loss: 1.439
[3, 17601]  training loss: 1.443
[3, 17801]  training loss: 1.438
[3, 18001]  training loss: 1.442
[3, 18201]  training loss: 1.444
[3, 18401]  training loss: 1.449
[3, 18601]  training loss: 1.447
[3, 18801]  training loss: 1.453
[3, 19001]  training loss: 1.433
[3, 19201]  training loss: 1.443
[3, 19401]  training loss: 1.431
[3, 19601]  training loss: 1.443
[3, 19801]  training loss: 1.432
[3, 20001]  training loss: 1.429
[3, 20201]  training loss: 1.431
[3, 20401]  training loss: 1.428
[3, 20601]  training loss: 1.442
[3, 20801]  training loss: 1.436
[3, 21001]  training loss: 1.446
[3, 21201]  training loss: 1.434
[3, 21401]  training loss: 1.445
[3, 21601]  training loss: 1.433
[3, 21801]  training loss: 1.447
[3, 22001]  training loss: 1.445
[3, 22201]  training loss: 1.433
[3,     1]  validation loss: 1.525, metric: 22370.047
[3,   201]  validation loss: 1.531, metric: 22370.056
[3,   401]  validation loss: 1.527, metric: 22370.045
[4,     1]  training loss: 1.452
[4,   201]  training loss: 1.446
[4,   401]  training loss: 1.442
[4,   601]  training loss: 1.438
[4,   801]  training loss: 1.425
[4,  1001]  training loss: 1.439
[4,  1201]  training loss: 1.426
[4,  1401]  training loss: 1.427
[4,  1601]  training loss: 1.442
[4,  1801]  training loss: 1.440
[4,  2001]  training loss: 1.435
[4,  2201]  training loss: 1.414
[4,  2401]  training loss: 1.457
[4,  2601]  training loss: 1.441
[4,  2801]  training loss: 1.444
[4,  3001]  training loss: 1.431
[4,  3201]  training loss: 1.442
[4,  3401]  training loss: 1.438
[4,  3601]  training loss: 1.442
[4,  3801]  training loss: 1.443
[4,  4001]  training loss: 1.431
[4,  4201]  training loss: 1.451
[4,  4401]  training loss: 1.436
[4,  4601]  training loss: 1.446
[4,  4801]  training loss: 1.440
[4,  5001]  training loss: 1.447
[4,  5201]  training loss: 1.438
[4,  5401]  training loss: 1.430
[4,  5601]  training loss: 1.448
[4,  5801]  training loss: 1.432
[4,  6001]  training loss: 1.436
[4,  6201]  training loss: 1.453
[4,  6401]  training loss: 1.444
[4,  6601]  training loss: 1.437
[4,  6801]  training loss: 1.438
[4,  7001]  training loss: 1.443
[4,  7201]  training loss: 1.438
[4,  7401]  training loss: 1.437
[4,  7601]  training loss: 1.433
[4,  7801]  training loss: 1.435
[4,  8001]  training loss: 1.444
[4,  8201]  training loss: 1.441
[4,  8401]  training loss: 1.420
[4,  8601]  training loss: 1.433
[4,  8801]  training loss: 1.447
[4,  9001]  training loss: 1.442
[4,  9201]  training loss: 1.430
[4,  9401]  training loss: 1.440
[4,  9601]  training loss: 1.426
[4,  9801]  training loss: 1.436
[4, 10001]  training loss: 1.439
[4, 10201]  training loss: 1.447
[4, 10401]  training loss: 1.433
[4, 10601]  training loss: 1.445
[4, 10801]  training loss: 1.431
[4, 11001]  training loss: 1.444
[4, 11201]  training loss: 1.433
[4, 11401]  training loss: 1.448
[4, 11601]  training loss: 1.446
[4, 11801]  training loss: 1.452
[4, 12001]  training loss: 1.441
[4, 12201]  training loss: 1.440
[4, 12401]  training loss: 1.444
[4, 12601]  training loss: 1.432
[4, 12801]  training loss: 1.439
[4, 13001]  training loss: 1.441
[4, 13201]  training loss: 1.434
[4, 13401]  training loss: 1.442
[4, 13601]  training loss: 1.439
[4, 13801]  training loss: 1.439
[4, 14001]  training loss: 1.439
[4, 14201]  training loss: 1.441
[4, 14401]  training loss: 1.440
[4, 14601]  training loss: 1.439
[4, 14801]  training loss: 1.444
[4, 15001]  training loss: 1.432
[4, 15201]  training loss: 1.436
[4, 15401]  training loss: 1.443
[4, 15601]  training loss: 1.440
[4, 15801]  training loss: 1.452
[4, 16001]  training loss: 1.449
[4, 16201]  training loss: 1.453
[4, 16401]  training loss: 1.451
[4, 16601]  training loss: 1.435
[4, 16801]  training loss: 1.444
[4, 17001]  training loss: 1.437
[4, 17201]  training loss: 1.450
[4, 17401]  training loss: 1.431
[4, 17601]  training loss: 1.445
[4, 17801]  training loss: 1.433
[4, 18001]  training loss: 1.443
[4, 18201]  training loss: 1.435
[4, 18401]  training loss: 1.437
[4, 18601]  training loss: 1.453
[4, 18801]  training loss: 1.444
[4, 19001]  training loss: 1.413
[4, 19201]  training loss: 1.436
[4, 19401]  training loss: 1.434
[4, 19601]  training loss: 1.439
[4, 19801]  training loss: 1.434
[4, 20001]  training loss: 1.432
[4, 20201]  training loss: 1.438
[4, 20401]  training loss: 1.444
[4, 20601]  training loss: 1.443
[4, 20801]  training loss: 1.455
[4, 21001]  training loss: 1.444
[4, 21201]  training loss: 1.442
[4, 21401]  training loss: 1.432
[4, 21601]  training loss: 1.432
[4, 21801]  training loss: 1.441
[4, 22001]  training loss: 1.436
[4, 22201]  training loss: 1.439
[4,     1]  validation loss: 1.504, metric: 31374.550
[4,   201]  validation loss: 1.502, metric: 31375.015
[4,   401]  validation loss: 1.502, metric: 31374.405
[5,     1]  training loss: 1.424
[5,   201]  training loss: 1.434
[5,   401]  training loss: 1.440
[5,   601]  training loss: 1.435
[5,   801]  training loss: 1.437
[5,  1001]  training loss: 1.448
[5,  1201]  training loss: 1.424
[5,  1401]  training loss: 1.438
[5,  1601]  training loss: 1.435
[5,  1801]  training loss: 1.434
[5,  2001]  training loss: 1.432
[5,  2201]  training loss: 1.442
[5,  2401]  training loss: 1.433
[5,  2601]  training loss: 1.441
[5,  2801]  training loss: 1.438
[5,  3001]  training loss: 1.433
[5,  3201]  training loss: 1.437
[5,  3401]  training loss: 1.406
[5,  3601]  training loss: 1.418
[5,  3801]  training loss: 1.441
[5,  4001]  training loss: 1.427
[5,  4201]  training loss: 1.434
[5,  4401]  training loss: 1.428
[5,  4601]  training loss: 1.414
[5,  4801]  training loss: 1.446
[5,  5001]  training loss: 1.434
[5,  5201]  training loss: 1.439
[5,  5401]  training loss: 1.423
[5,  5601]  training loss: 1.429
[5,  5801]  training loss: 1.426
[5,  6001]  training loss: 1.437
[5,  6201]  training loss: 1.431
[5,  6401]  training loss: 1.436
[5,  6601]  training loss: 1.449
[5,  6801]  training loss: 1.445
[5,  7001]  training loss: 1.428
[5,  7201]  training loss: 1.419
[5,  7401]  training loss: 1.447
[5,  7601]  training loss: 1.430
[5,  7801]  training loss: 1.450
[5,  8001]  training loss: 1.441
[5,  8201]  training loss: 1.418
[5,  8401]  training loss: 1.428
[5,  8601]  training loss: 1.431
[5,  8801]  training loss: 1.439
[5,  9001]  training loss: 1.427
[5,  9201]  training loss: 1.438
[5,  9401]  training loss: 1.436
[5,  9601]  training loss: 1.428
[5,  9801]  training loss: 1.426
[5, 10001]  training loss: 1.431
[5, 10201]  training loss: 1.438
[5, 10401]  training loss: 1.436
[5, 10601]  training loss: 1.433
[5, 10801]  training loss: 1.433
[5, 11001]  training loss: 1.420
[5, 11201]  training loss: 1.437
[5, 11401]  training loss: 1.434
[5, 11601]  training loss: 1.428
[5, 11801]  training loss: 1.428
[5, 12001]  training loss: 1.443
[5, 12201]  training loss: 1.432
[5, 12401]  training loss: 1.433
[5, 12601]  training loss: 1.428
[5, 12801]  training loss: 1.433
[5, 13001]  training loss: 1.437
[5, 13201]  training loss: 1.431
[5, 13401]  training loss: 1.427
[5, 13601]  training loss: 1.437
[5, 13801]  training loss: 1.428
[5, 14001]  training loss: 1.436
[5, 14201]  training loss: 1.440
[5, 14401]  training loss: 1.418
[5, 14601]  training loss: 1.444
[5, 14801]  training loss: 1.436
[5, 15001]  training loss: 1.427
[5, 15201]  training loss: 1.438
[5, 15401]  training loss: 1.432
[5, 15601]  training loss: 1.431
[5, 15801]  training loss: 1.424
[5, 16001]  training loss: 1.434
[5, 16201]  training loss: 1.421
[5, 16401]  training loss: 1.437
[5, 16601]  training loss: 1.432
[5, 16801]  training loss: 1.437
[5, 17001]  training loss: 1.442
[5, 17201]  training loss: 1.413
[5, 17401]  training loss: 1.440
[5, 17601]  training loss: 1.435
[5, 17801]  training loss: 1.427
[5, 18001]  training loss: 1.433
[5, 18201]  training loss: 1.435
[5, 18401]  training loss: 1.436
[5, 18601]  training loss: 1.426
[5, 18801]  training loss: 1.447
[5, 19001]  training loss: 1.445
[5, 19201]  training loss: 1.437
[5, 19401]  training loss: 1.442
[5, 19601]  training loss: 1.433
[5, 19801]  training loss: 1.442
[5, 20001]  training loss: 1.419
[5, 20201]  training loss: 1.440
[5, 20401]  training loss: 1.445
[5, 20601]  training loss: 1.432
[5, 20801]  training loss: 1.429
[5, 21001]  training loss: 1.431
[5, 21201]  training loss: 1.444
[5, 21401]  training loss: 1.413
[5, 21601]  training loss: 1.452
[5, 21801]  training loss: 1.432
[5, 22001]  training loss: 1.417
[5, 22201]  training loss: 1.452
[5,     1]  validation loss: 1.519, metric: 24161.071
[5,   201]  validation loss: 1.516, metric: 24213.171
[5,   401]  validation loss: 1.513, metric: 24161.958
[6,     1]  training loss: 1.442
[6,   201]  training loss: 1.431
[6,   401]  training loss: 1.421
[6,   601]  training loss: 1.435
[6,   801]  training loss: 1.435
[6,  1001]  training loss: 1.437
[6,  1201]  training loss: 1.440
[6,  1401]  training loss: 1.432
[6,  1601]  training loss: 1.444
[6,  1801]  training loss: 1.431
[6,  2001]  training loss: 1.428
[6,  2201]  training loss: 1.443
[6,  2401]  training loss: 1.426
[6,  2601]  training loss: 1.439
[6,  2801]  training loss: 1.437
[6,  3001]  training loss: 1.442
[6,  3201]  training loss: 1.431
[6,  3401]  training loss: 1.437
[6,  3601]  training loss: 1.425
[6,  3801]  training loss: 1.433
[6,  4001]  training loss: 1.425
[6,  4201]  training loss: 1.440
[6,  4401]  training loss: 1.438
[6,  4601]  training loss: 1.445
[6,  4801]  training loss: 1.434
[6,  5001]  training loss: 1.440
[6,  5201]  training loss: 1.437
[6,  5401]  training loss: 1.431
[6,  5601]  training loss: 1.432
[6,  5801]  training loss: 1.437
[6,  6001]  training loss: 1.442
[6,  6201]  training loss: 1.445
[6,  6401]  training loss: 1.440
[6,  6601]  training loss: 1.446
[6,  6801]  training loss: 1.434
[6,  7001]  training loss: 1.442
[6,  7201]  training loss: 1.432
[6,  7401]  training loss: 1.447
[6,  7601]  training loss: 1.446
[6,  7801]  training loss: 1.450
[6,  8001]  training loss: 1.423
[6,  8201]  training loss: 1.438
[6,  8401]  training loss: 1.433
[6,  8601]  training loss: 1.440
[6,  8801]  training loss: 1.437
[6,  9001]  training loss: 1.445
[6,  9201]  training loss: 1.439
[6,  9401]  training loss: 1.441
[6,  9601]  training loss: 1.444
[6,  9801]  training loss: 1.426
[6, 10001]  training loss: 1.436
[6, 10201]  training loss: 1.441
[6, 10401]  training loss: 1.445
[6, 10601]  training loss: 1.436
[6, 10801]  training loss: 1.434
[6, 11001]  training loss: 1.444
[6, 11201]  training loss: 1.442
[6, 11401]  training loss: 1.443
[6, 11601]  training loss: 1.445
[6, 11801]  training loss: 1.427
[6, 12001]  training loss: 1.432
[6, 12201]  training loss: 1.432
[6, 12401]  training loss: 1.432
[6, 12601]  training loss: 1.443
[6, 12801]  training loss: 1.435
[6, 13001]  training loss: 1.438
[6, 13201]  training loss: 1.436
[6, 13401]  training loss: 1.414
[6, 13601]  training loss: 1.438
[6, 13801]  training loss: 1.425
[6, 14001]  training loss: 1.441
[6, 14201]  training loss: 1.446
[6, 14401]  training loss: 1.432
[6, 14601]  training loss: 1.430
[6, 14801]  training loss: 1.418
[6, 15001]  training loss: 1.421
[6, 15201]  training loss: 1.427
[6, 15401]  training loss: 1.442
[6, 15601]  training loss: 1.418
[6, 15801]  training loss: 1.436
[6, 16001]  training loss: 1.445
[6, 16201]  training loss: 1.440
[6, 16401]  training loss: 1.411
[6, 16601]  training loss: 1.431
[6, 16801]  training loss: 1.432
[6, 17001]  training loss: 1.433
[6, 17201]  training loss: 1.440
[6, 17401]  training loss: 1.444
[6, 17601]  training loss: 1.435
[6, 17801]  training loss: 1.445
[6, 18001]  training loss: 1.426
[6, 18201]  training loss: 1.440
[6, 18401]  training loss: 1.438
[6, 18601]  training loss: 1.440
[6, 18801]  training loss: 1.422
[6, 19001]  training loss: 1.444
[6, 19201]  training loss: 1.445
[6, 19401]  training loss: 1.442
[6, 19601]  training loss: 1.437
[6, 19801]  training loss: 1.449
[6, 20001]  training loss: 1.436
[6, 20201]  training loss: 1.439
[6, 20401]  training loss: 1.429
[6, 20601]  training loss: 1.448
[6, 20801]  training loss: 1.431
[6, 21001]  training loss: 1.435
[6, 21201]  training loss: 1.439
[6, 21401]  training loss: 1.439
[6, 21601]  training loss: 1.430
[6, 21801]  training loss: 1.438
[6, 22001]  training loss: 1.438
[6, 22201]  training loss: 1.436
[6,     1]  validation loss: 1.517, metric: 16731.577
[6,   201]  validation loss: 1.518, metric: 16731.901
[6,   401]  validation loss: 1.517, metric: 16727.545
[7,     1]  training loss: 1.446
[7,   201]  training loss: 1.458
[7,   401]  training loss: 1.434
[7,   601]  training loss: 1.443
[7,   801]  training loss: 1.413
[7,  1001]  training loss: 1.414
[7,  1201]  training loss: 1.439
[7,  1401]  training loss: 1.442
[7,  1601]  training loss: 1.433
[7,  1801]  training loss: 1.448
[7,  2001]  training loss: 1.438
[7,  2201]  training loss: 1.434
[7,  2401]  training loss: 1.430
[7,  2601]  training loss: 1.431
[7,  2801]  training loss: 1.444
[7,  3001]  training loss: 1.442
[7,  3201]  training loss: 1.441
[7,  3401]  training loss: 1.443
[7,  3601]  training loss: 1.433
[7,  3801]  training loss: 1.433
[7,  4001]  training loss: 1.440
[7,  4201]  training loss: 1.442
[7,  4401]  training loss: 1.433
[7,  4601]  training loss: 1.442
[7,  4801]  training loss: 1.430
[7,  5001]  training loss: 1.439
[7,  5201]  training loss: 1.445
[7,  5401]  training loss: 1.436
[7,  5601]  training loss: 1.433
[7,  5801]  training loss: 1.444
[7,  6001]  training loss: 1.435
[7,  6201]  training loss: 1.436
[7,  6401]  training loss: 1.436
[7,  6601]  training loss: 1.445
[7,  6801]  training loss: 1.437
[7,  7001]  training loss: 1.421
[7,  7201]  training loss: 1.448
[7,  7401]  training loss: 1.446
[7,  7601]  training loss: 1.448
[7,  7801]  training loss: 1.437
[7,  8001]  training loss: 1.429
[7,  8201]  training loss: 1.428
[7,  8401]  training loss: 1.426
[7,  8601]  training loss: 1.429
[7,  8801]  training loss: 1.431
[7,  9001]  training loss: 1.439
[7,  9201]  training loss: 1.437
[7,  9401]  training loss: 1.435
[7,  9601]  training loss: 1.445
[7,  9801]  training loss: 1.439
[7, 10001]  training loss: 1.428
[7, 10201]  training loss: 1.446
[7, 10401]  training loss: 1.441
[7, 10601]  training loss: 1.442
[7, 10801]  training loss: 1.428
[7, 11001]  training loss: 1.451
[7, 11201]  training loss: 1.436
[7, 11401]  training loss: 1.435
[7, 11601]  training loss: 1.442
[7, 11801]  training loss: 1.442
[7, 12001]  training loss: 1.428
[7, 12201]  training loss: 1.439
[7, 12401]  training loss: 1.436
[7, 12601]  training loss: 1.432
[7, 12801]  training loss: 1.441
[7, 13001]  training loss: 1.445
[7, 13201]  training loss: 1.431
[7, 13401]  training loss: 1.439
[7, 13601]  training loss: 1.432
[7, 13801]  training loss: 1.442
[7, 14001]  training loss: 1.448
[7, 14201]  training loss: 1.436
[7, 14401]  training loss: 1.436
[7, 14601]  training loss: 1.433
[7, 14801]  training loss: 1.425
[7, 15001]  training loss: 1.433
[7, 15201]  training loss: 1.435
[7, 15401]  training loss: 1.433
[7, 15601]  training loss: 1.435
[7, 15801]  training loss: 1.439
[7, 16001]  training loss: 1.445
[7, 16201]  training loss: 1.443
[7, 16401]  training loss: 1.447
[7, 16601]  training loss: 1.438
[7, 16801]  training loss: 1.439
[7, 17001]  training loss: 1.443
[7, 17201]  training loss: 1.438
[7, 17401]  training loss: 1.443
[7, 17601]  training loss: 1.447
[7, 17801]  training loss: 1.437
[7, 18001]  training loss: 1.440
[7, 18201]  training loss: 1.442
[7, 18401]  training loss: 1.438
[7, 18601]  training loss: 1.444
[7, 18801]  training loss: 1.440
[7, 19001]  training loss: 1.446
[7, 19201]  training loss: 1.434
[7, 19401]  training loss: 1.437
[7, 19601]  training loss: 1.438
[7, 19801]  training loss: 1.433
[7, 20001]  training loss: 1.437
[7, 20201]  training loss: 1.425
[7, 20401]  training loss: 1.436
[7, 20601]  training loss: 1.442
[7, 20801]  training loss: 1.442
[7, 21001]  training loss: 1.439
[7, 21201]  training loss: 1.435
[7, 21401]  training loss: 1.431
[7, 21601]  training loss: 1.438
[7, 21801]  training loss: 1.440
[7, 22001]  training loss: 1.436
[7, 22201]  training loss: 1.437
[7,     1]  validation loss: 1.503, metric: 22282.888
[7,   201]  validation loss: 1.506, metric: 22282.072
[7,   401]  validation loss: 1.505, metric: 22280.824
[8,     1]  training loss: 1.423
[8,   201]  training loss: 1.447
[8,   401]  training loss: 1.437
[8,   601]  training loss: 1.438
[8,   801]  training loss: 1.438
[8,  1001]  training loss: 1.440
[8,  1201]  training loss: 1.439
[8,  1401]  training loss: 1.438
[8,  1601]  training loss: 1.419
[8,  1801]  training loss: 1.451
[8,  2001]  training loss: 1.446
[8,  2201]  training loss: 1.450
[8,  2401]  training loss: 1.443
[8,  2601]  training loss: 1.428
[8,  2801]  training loss: 1.437
[8,  3001]  training loss: 1.442
[8,  3201]  training loss: 1.450
[8,  3401]  training loss: 1.443
[8,  3601]  training loss: 1.443
[8,  3801]  training loss: 1.435
[8,  4001]  training loss: 1.454
[8,  4201]  training loss: 1.439
[8,  4401]  training loss: 1.437
[8,  4601]  training loss: 1.435
[8,  4801]  training loss: 1.433
[8,  5001]  training loss: 1.435
[8,  5201]  training loss: 1.406
[8,  5401]  training loss: 1.416
[8,  5601]  training loss: 1.436
[8,  5801]  training loss: 1.414
[8,  6001]  training loss: 1.410
[8,  6201]  training loss: 1.418
[8,  6401]  training loss: 1.424
[8,  6601]  training loss: 1.416
[8,  6801]  training loss: 1.432
[8,  7001]  training loss: 1.431
[8,  7201]  training loss: 1.419
[8,  7401]  training loss: 1.432
[8,  7601]  training loss: 1.429
[8,  7801]  training loss: 1.427
[8,  8001]  training loss: 1.425
[8,  8201]  training loss: 1.439
[8,  8401]  training loss: 1.431
[8,  8601]  training loss: 1.432
[8,  8801]  training loss: 1.426
[8,  9001]  training loss: 1.431
[8,  9201]  training loss: 1.421
[8,  9401]  training loss: 1.444
[8,  9601]  training loss: 1.444
[8,  9801]  training loss: 1.434
[8, 10001]  training loss: 1.432
[8, 10201]  training loss: 1.442
[8, 10401]  training loss: 1.427
[8, 10601]  training loss: 1.438
[8, 10801]  training loss: 1.427
[8, 11001]  training loss: 1.436
[8, 11201]  training loss: 1.434
[8, 11401]  training loss: 1.435
[8, 11601]  training loss: 1.437
[8, 11801]  training loss: 1.440
[8, 12001]  training loss: 1.434
[8, 12201]  training loss: 1.426
[8, 12401]  training loss: 1.428
[8, 12601]  training loss: 1.419
[8, 12801]  training loss: 1.429
[8, 13001]  training loss: 1.443
[8, 13201]  training loss: 1.439
[8, 13401]  training loss: 1.428
[8, 13601]  training loss: 1.434
[8, 13801]  training loss: 1.431
[8, 14001]  training loss: 1.420
[8, 14201]  training loss: 1.440
[8, 14401]  training loss: 1.431
[8, 14601]  training loss: 1.419
[8, 14801]  training loss: 1.426
[8, 15001]  training loss: 1.438
[8, 15201]  training loss: 1.432
[8, 15401]  training loss: 1.442
[8, 15601]  training loss: 1.435
[8, 15801]  training loss: 1.451
[8, 16001]  training loss: 1.419
[8, 16201]  training loss: 1.427
[8, 16401]  training loss: 1.434
[8, 16601]  training loss: 1.440
[8, 16801]  training loss: 1.437
[8, 17001]  training loss: 1.437
[8, 17201]  training loss: 1.436
[8, 17401]  training loss: 1.442
[8, 17601]  training loss: 1.415
[8, 17801]  training loss: 1.439
[8, 18001]  training loss: 1.440
[8, 18201]  training loss: 1.428
[8, 18401]  training loss: 1.421
[8, 18601]  training loss: 1.415
[8, 18801]  training loss: 1.433
[8, 19001]  training loss: 1.432
[8, 19201]  training loss: 1.434
[8, 19401]  training loss: 1.428
[8, 19601]  training loss: 1.437
[8, 19801]  training loss: 1.435
[8, 20001]  training loss: 1.421
[8, 20201]  training loss: 1.434
[8, 20401]  training loss: 1.435
[8, 20601]  training loss: 1.426
[8, 20801]  training loss: 1.424
[8, 21001]  training loss: 1.430
[8, 21201]  training loss: 1.426
[8, 21401]  training loss: 1.438
[8, 21601]  training loss: 1.423
[8, 21801]  training loss: 1.435
[8, 22001]  training loss: 1.437
[8, 22201]  training loss: 1.446
[8,     1]  validation loss: 1.509, metric: 28253.737
[8,   201]  validation loss: 1.504, metric: 28253.762
[8,   401]  validation loss: 1.507, metric: 28253.516
[9,     1]  training loss: 1.436
[9,   201]  training loss: 1.437
[9,   401]  training loss: 1.423
[9,   601]  training loss: 1.432
[9,   801]  training loss: 1.437
[9,  1001]  training loss: 1.427
[9,  1201]  training loss: 1.434
[9,  1401]  training loss: 1.418
[9,  1601]  training loss: 1.441
[9,  1801]  training loss: 1.433
[9,  2001]  training loss: 1.426
[9,  2201]  training loss: 1.431
[9,  2401]  training loss: 1.433
[9,  2601]  training loss: 1.433
[9,  2801]  training loss: 1.438
[9,  3001]  training loss: 1.429
[9,  3201]  training loss: 1.430
[9,  3401]  training loss: 1.434
[9,  3601]  training loss: 1.444
[9,  3801]  training loss: 1.411
[9,  4001]  training loss: 1.433
[9,  4201]  training loss: 1.413
[9,  4401]  training loss: 1.427
[9,  4601]  training loss: 1.438
[9,  4801]  training loss: 1.436
[9,  5001]  training loss: 1.427
[9,  5201]  training loss: 1.431
[9,  5401]  training loss: 1.443
[9,  5601]  training loss: 1.420
[9,  5801]  training loss: 1.446
[9,  6001]  training loss: 1.439
[9,  6201]  training loss: 1.432
[9,  6401]  training loss: 1.443
[9,  6601]  training loss: 1.418
[9,  6801]  training loss: 1.430
[9,  7001]  training loss: 1.435
[9,  7201]  training loss: 1.428
[9,  7401]  training loss: 1.420
[9,  7601]  training loss: 1.441
[9,  7801]  training loss: 1.417
[9,  8001]  training loss: 1.430
[9,  8201]  training loss: 1.436
[9,  8401]  training loss: 1.429
[9,  8601]  training loss: 1.433
[9,  8801]  training loss: 1.435
[9,  9001]  training loss: 1.438
[9,  9201]  training loss: 1.443
[9,  9401]  training loss: 1.422
[9,  9601]  training loss: 1.420
[9,  9801]  training loss: 1.405
[9, 10001]  training loss: 1.424
[9, 10201]  training loss: 1.440
[9, 10401]  training loss: 1.409
[9, 10601]  training loss: 1.436
[9, 10801]  training loss: 1.439
[9, 11001]  training loss: 1.432
[9, 11201]  training loss: 1.428
[9, 11401]  training loss: 1.429
[9, 11601]  training loss: 1.435
[9, 11801]  training loss: 1.410
[9, 12001]  training loss: 1.444
[9, 12201]  training loss: 1.421
[9, 12401]  training loss: 1.422
[9, 12601]  training loss: 1.435
[9, 12801]  training loss: 1.439
[9, 13001]  training loss: 1.438
[9, 13201]  training loss: 1.412
[9, 13401]  training loss: 1.433
[9, 13601]  training loss: 1.434
[9, 13801]  training loss: 1.419
[9, 14001]  training loss: 1.444
[9, 14201]  training loss: 1.435
[9, 14401]  training loss: 1.433
[9, 14601]  training loss: 1.436
[9, 14801]  training loss: 1.424
[9, 15001]  training loss: 1.439
[9, 15201]  training loss: 1.428
[9, 15401]  training loss: 1.427
[9, 15601]  training loss: 1.433
[9, 15801]  training loss: 1.428
[9, 16001]  training loss: 1.421
[9, 16201]  training loss: 1.435
[9, 16401]  training loss: 1.433
[9, 16601]  training loss: 1.462
[9, 16801]  training loss: 1.436
[9, 17001]  training loss: 1.435
[9, 17201]  training loss: 1.446
[9, 17401]  training loss: 1.440
[9, 17601]  training loss: 1.429
[9, 17801]  training loss: 1.429
[9, 18001]  training loss: 1.437
[9, 18201]  training loss: 1.443
[9, 18401]  training loss: 1.436
[9, 18601]  training loss: 1.426
[9, 18801]  training loss: 1.427
[9, 19001]  training loss: 1.440
[9, 19201]  training loss: 1.435
[9, 19401]  training loss: 1.432
[9, 19601]  training loss: 1.435
[9, 19801]  training loss: 1.435
[9, 20001]  training loss: 1.435
[9, 20201]  training loss: 1.432
[9, 20401]  training loss: 1.432
[9, 20601]  training loss: 1.427
[9, 20801]  training loss: 1.435
[9, 21001]  training loss: 1.445
[9, 21201]  training loss: 1.409
[9, 21401]  training loss: 1.440
[9, 21601]  training loss: 1.404
[9, 21801]  training loss: 1.429
[9, 22001]  training loss: 1.416
[9, 22201]  training loss: 1.432
[9,     1]  validation loss: 1.514, metric: 18068.024
[9,   201]  validation loss: 1.513, metric: 17931.908
[9,   401]  validation loss: 1.515, metric: 18070.626
[10,     1]  training loss: 1.437
[10,   201]  training loss: 1.421
[10,   401]  training loss: 1.434
[10,   601]  training loss: 1.435
[10,   801]  training loss: 1.436
[10,  1001]  training loss: 1.438
[10,  1201]  training loss: 1.430
[10,  1401]  training loss: 1.434
[10,  1601]  training loss: 1.444
[10,  1801]  training loss: 1.428
[10,  2001]  training loss: 1.429
[10,  2201]  training loss: 1.423
[10,  2401]  training loss: 1.435
[10,  2601]  training loss: 1.432
[10,  2801]  training loss: 1.436
[10,  3001]  training loss: 1.427
[10,  3201]  training loss: 1.434
[10,  3401]  training loss: 1.424
[10,  3601]  training loss: 1.435
[10,  3801]  training loss: 1.415
[10,  4001]  training loss: 1.420
[10,  4201]  training loss: 1.441
[10,  4401]  training loss: 1.420
[10,  4601]  training loss: 1.432
[10,  4801]  training loss: 1.435
[10,  5001]  training loss: 1.416
[10,  5201]  training loss: 1.417
[10,  5401]  training loss: 1.430
[10,  5601]  training loss: 1.434
[10,  5801]  training loss: 1.444
[10,  6001]  training loss: 1.418
[10,  6201]  training loss: 1.428
[10,  6401]  training loss: 1.431
[10,  6601]  training loss: 1.433
[10,  6801]  training loss: 1.438
[10,  7001]  training loss: 1.436
[10,  7201]  training loss: 1.434
[10,  7401]  training loss: 1.427
[10,  7601]  training loss: 1.431
[10,  7801]  training loss: 1.426
[10,  8001]  training loss: 1.431
[10,  8201]  training loss: 1.439
[10,  8401]  training loss: 1.423
[10,  8601]  training loss: 1.442
[10,  8801]  training loss: 1.428
[10,  9001]  training loss: 1.426
[10,  9201]  training loss: 1.426
[10,  9401]  training loss: 1.450
[10,  9601]  training loss: 1.435
[10,  9801]  training loss: 1.439
[10, 10001]  training loss: 1.417
[10, 10201]  training loss: 1.436
[10, 10401]  training loss: 1.428
[10, 10601]  training loss: 1.437
[10, 10801]  training loss: 1.436
[10, 11001]  training loss: 1.437
[10, 11201]  training loss: 1.430
[10, 11401]  training loss: 1.430
[10, 11601]  training loss: 1.429
[10, 11801]  training loss: 1.426
[10, 12001]  training loss: 1.436
[10, 12201]  training loss: 1.429
[10, 12401]  training loss: 1.420
[10, 12601]  training loss: 1.440
[10, 12801]  training loss: 1.434
[10, 13001]  training loss: 1.419
[10, 13201]  training loss: 1.445
[10, 13401]  training loss: 1.423
[10, 13601]  training loss: 1.414
[10, 13801]  training loss: 1.433
[10, 14001]  training loss: 1.437
[10, 14201]  training loss: 1.430
[10, 14401]  training loss: 1.423
[10, 14601]  training loss: 1.431
[10, 14801]  training loss: 1.437
[10, 15001]  training loss: 1.436
[10, 15201]  training loss: 1.430
[10, 15401]  training loss: 1.430
[10, 15601]  training loss: 1.435
[10, 15801]  training loss: 1.437
[10, 16001]  training loss: 1.416
[10, 16201]  training loss: 1.444
[10, 16401]  training loss: 1.429
[10, 16601]  training loss: 1.434
[10, 16801]  training loss: 1.420
[10, 17001]  training loss: 1.438
[10, 17201]  training loss: 1.417
[10, 17401]  training loss: 1.429
[10, 17601]  training loss: 1.442
[10, 17801]  training loss: 1.412
[10, 18001]  training loss: 1.434
[10, 18201]  training loss: 1.429
[10, 18401]  training loss: 1.436
[10, 18601]  training loss: 1.433
[10, 18801]  training loss: 1.441
[10, 19001]  training loss: 1.436
[10, 19201]  training loss: 1.439
[10, 19401]  training loss: 1.423
[10, 19601]  training loss: 1.436
[10, 19801]  training loss: 1.430
[10, 20001]  training loss: 1.432
[10, 20201]  training loss: 1.437
[10, 20401]  training loss: 1.431
[10, 20601]  training loss: 1.434
[10, 20801]  training loss: 1.443
[10, 21001]  training loss: 1.433
[10, 21201]  training loss: 1.433
[10, 21401]  training loss: 1.425
[10, 21601]  training loss: 1.430
[10, 21801]  training loss: 1.436
[10, 22001]  training loss: 1.436
[10, 22201]  training loss: 1.438
[10,     1]  validation loss: 1.514, metric: 40778.792
[10,   201]  validation loss: 1.514, metric: 41077.128
[10,   401]  validation loss: 1.514, metric: 41233.395
----saving model-----
Traceback (most recent call last):
  File "/home/sb56/efficient_vision/stsgcn/efficient_vision_project_debugging/main_aist_music.py", line 219, in <module>
    train()
  File "/home/sb56/efficient_vision/stsgcn/efficient_vision_project_debugging/main_aist_music.py", line 144, in train
    torch.save(model.state_dict(),os.path.join(args.model_path,model_name+"e%d_v%.3f_t%.3f_m%.3f" % (epoch,curr_val_loss, curr_train_loss, curr_metric)))
  File "/home/sb56/anaconda3/lib/python3.9/site-packages/torch/serialization.py", line 377, in save
    with _open_file_like(f, 'wb') as opened_file:
  File "/home/sb56/anaconda3/lib/python3.9/site-packages/torch/serialization.py", line 231, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/sb56/anaconda3/lib/python3.9/site-packages/torch/serialization.py", line 212, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './checkpoints/CKPT_3D_AIST/aist_music_20frames_ckpte9_v1.515_t1.431_m41040.854'
